{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Data Processing and loading\n",
    "data_ca = pd.read_csv(\"./Data/data_change_heart_disease_categorical.csv\")\n",
    "data_nu = pd.read_csv(\"./Data/data_change_heart_disease_numerical.csv\")\n",
    "\n",
    "# Test train split and store into dictionaries\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split(df,test_size=0.2):\n",
    "    X = df.iloc[:,0:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size,random_state=43)\n",
    "    data_dic = {}\n",
    "    data_dic[\"X_train\"]=X_train\n",
    "    data_dic[\"X_test\"]=X_test\n",
    "    data_dic[\"y_train\"]=y_train\n",
    "    data_dic[\"y_test\"]=y_test\n",
    "    return data_dic\n",
    "data_ca = split(data_ca)\n",
    "data_nu = split(data_nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ca[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nu = {}\n",
    "def feature_extract_nu(X_train,y_train):\n",
    "    features = X_train.columns\n",
    "    HD_idx = y_train==\"Heart disease\"\n",
    "    Normal_idx = y_train==\"Normal\"\n",
    "    for i in features:\n",
    "        feature_HD = X_train.loc[HD_idx,i]\n",
    "        feature_Normal = X_train.loc[Normal_idx,i]\n",
    "        \n",
    "        prediction={}\n",
    "        prediction[i]=pd.DataFrame()\n",
    "        prediction[i][\"Heart disease\"]=[feature_HD.mean(),feature_HD.std()]\n",
    "        prediction[i][\"Normal\"]=[feature_Normal.mean(),feature_Normal.std()]\n",
    "        prediction[i].index=[\"mean\",\"sd\"]\n",
    "    return prediction\n",
    "prediction_nu = feature_extract_nu(data_nu[\"X_train\"],data_nu[\"y_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Heart disease    0.707107\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame()\n",
    "a[\"Heart disease\"]=[1,2]\n",
    "a.index=[\"a\",\"b\"]\n",
    "a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None, *, equal_nan=True)\n",
      "    Find the unique elements of an array.\n",
      "    \n",
      "    Returns the sorted unique elements of an array. There are three optional\n",
      "    outputs in addition to the unique elements:\n",
      "    \n",
      "    * the indices of the input array that give the unique values\n",
      "    * the indices of the unique array that reconstruct the input array\n",
      "    * the number of times each unique value comes up in the input array\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    ar : array_like\n",
      "        Input array. Unless `axis` is specified, this will be flattened if it\n",
      "        is not already 1-D.\n",
      "    return_index : bool, optional\n",
      "        If True, also return the indices of `ar` (along the specified axis,\n",
      "        if provided, or in the flattened array) that result in the unique array.\n",
      "    return_inverse : bool, optional\n",
      "        If True, also return the indices of the unique array (for the specified\n",
      "        axis, if provided) that can be used to reconstruct `ar`.\n",
      "    return_counts : bool, optional\n",
      "        If True, also return the number of times each unique item appears\n",
      "        in `ar`.\n",
      "    axis : int or None, optional\n",
      "        The axis to operate on. If None, `ar` will be flattened. If an integer,\n",
      "        the subarrays indexed by the given axis will be flattened and treated\n",
      "        as the elements of a 1-D array with the dimension of the given axis,\n",
      "        see the notes for more details.  Object arrays or structured arrays\n",
      "        that contain objects are not supported if the `axis` kwarg is used. The\n",
      "        default is None.\n",
      "    \n",
      "        .. versionadded:: 1.13.0\n",
      "    \n",
      "    equal_nan : bool, optional\n",
      "        If True, collapses multiple NaN values in the return array into one.\n",
      "    \n",
      "        .. versionadded:: 1.24\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    unique : ndarray\n",
      "        The sorted unique values.\n",
      "    unique_indices : ndarray, optional\n",
      "        The indices of the first occurrences of the unique values in the\n",
      "        original array. Only provided if `return_index` is True.\n",
      "    unique_inverse : ndarray, optional\n",
      "        The indices to reconstruct the original array from the\n",
      "        unique array. Only provided if `return_inverse` is True.\n",
      "    unique_counts : ndarray, optional\n",
      "        The number of times each of the unique values comes up in the\n",
      "        original array. Only provided if `return_counts` is True.\n",
      "    \n",
      "        .. versionadded:: 1.9.0\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.lib.arraysetops : Module with a number of other functions for\n",
      "                            performing set operations on arrays.\n",
      "    repeat : Repeat elements of an array.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When an axis is specified the subarrays indexed by the axis are sorted.\n",
      "    This is done by making the specified axis the first dimension of the array\n",
      "    (move the axis to the first dimension to keep the order of the other axes)\n",
      "    and then flattening the subarrays in C order. The flattened subarrays are\n",
      "    then viewed as a structured type with each element given a label, with the\n",
      "    effect that we end up with a 1-D array of structured types that can be\n",
      "    treated in the same way as any other 1-D array. The result is that the\n",
      "    flattened subarrays are sorted in lexicographic order starting with the\n",
      "    first element.\n",
      "    \n",
      "    .. versionchanged: NumPy 1.21\n",
      "        If nan values are in the input array, a single nan is put\n",
      "        to the end of the sorted unique values.\n",
      "    \n",
      "        Also for complex arrays all NaN values are considered equivalent\n",
      "        (no matter whether the NaN is in the real or imaginary part).\n",
      "        As the representant for the returned array the smallest one in the\n",
      "        lexicographical order is chosen - see np.sort for how the lexicographical\n",
      "        order is defined for complex arrays.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.unique([1, 1, 2, 2, 3, 3])\n",
      "    array([1, 2, 3])\n",
      "    >>> a = np.array([[1, 1], [2, 3]])\n",
      "    >>> np.unique(a)\n",
      "    array([1, 2, 3])\n",
      "    \n",
      "    Return the unique rows of a 2D array\n",
      "    \n",
      "    >>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n",
      "    >>> np.unique(a, axis=0)\n",
      "    array([[1, 0, 0], [2, 3, 4]])\n",
      "    \n",
      "    Return the indices of the original array that give the unique values:\n",
      "    \n",
      "    >>> a = np.array(['a', 'b', 'b', 'c', 'a'])\n",
      "    >>> u, indices = np.unique(a, return_index=True)\n",
      "    >>> u\n",
      "    array(['a', 'b', 'c'], dtype='<U1')\n",
      "    >>> indices\n",
      "    array([0, 1, 3])\n",
      "    >>> a[indices]\n",
      "    array(['a', 'b', 'c'], dtype='<U1')\n",
      "    \n",
      "    Reconstruct the input array from the unique values and inverse:\n",
      "    \n",
      "    >>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
      "    >>> u, indices = np.unique(a, return_inverse=True)\n",
      "    >>> u\n",
      "    array([1, 2, 3, 4, 6])\n",
      "    >>> indices\n",
      "    array([0, 1, 4, 3, 1, 2, 1])\n",
      "    >>> u[indices]\n",
      "    array([1, 2, 6, 4, 2, 3, 2])\n",
      "    \n",
      "    Reconstruct the input values from the unique values and counts:\n",
      "    \n",
      "    >>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
      "    >>> values, counts = np.unique(a, return_counts=True)\n",
      "    >>> values\n",
      "    array([1, 2, 3, 4, 6])\n",
      "    >>> counts\n",
      "    array([1, 3, 1, 1, 1])\n",
      "    >>> np.repeat(values, counts)\n",
      "    array([1, 2, 2, 2, 3, 4, 6])    # original order not preserved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "y_pred\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
